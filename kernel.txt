kernel
conv
pooling
stride
padding
image resize
rgb concept
validation test set
overfitting
graph of val lose accurary
image augmentation to increase size of dataset
droupout method  randomly turning off the neuraons which are not required
early stopping
droupout
L1 L2 regularization
dropout dropconnect


resizing
color images
rgb image
convuoutions
max pooling
validation set

methods to prevent teh overfitting
early stopping
image augumentation
droupout






TRANSFER LEARNING :
Pre Build Models Alexnet 
Freezing the model : only last layer must train not intermediate data must change
Which model to choose:
Alexnet
Inception
Resnet
MobileNet

URL="https://tfhub.dev/google.tf2-preview/mobilenet_v2/feature_vector/2"
image_res=224
model=tf.keras.Sequential(
[
hub.KerasLayer(CLASSIFIER_,input_shape=(image_res)
])

freezing parameter
only last classification layer must update accordingly



Saving and Loading Models
TensorFlow Serving
TensorFlow lite
tensorflow.js
other language bindings
android 
respherry pi
directly web browser usage




Time Series Analysis:
Many can be in sequence.
Trend seasonality
some are unpredictable
white noise
find probality stributon then find its parameters

metrics mse is the most common 
errors=forecasts-actual
mse=np.square(errors).mean()
mae = np.abs(errors).mean()
mape=np.abs(errors/x_valid).mean()


Recurrent Neural Network
Forecasts -> Dense Layer -? Recurrent

Recurrent Layer:
activation is hyperbolic function 
bcz they have unstable gradients if we using function like the relu it would vanish . hyperbolic 10H function 

 


